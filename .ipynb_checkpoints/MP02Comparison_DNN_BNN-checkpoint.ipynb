{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from os import walk\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn import preprocessing\n",
    "# from keras import activations, initializers\n",
    "# from keras.layers import Layer\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import h5py\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_wave = 'no'\n",
    "modelID = 3\n",
    "# (0 for SCADA only, 1 for SCADA+Acc17, 2 for SCADA+Acc38, 3 for SCADA+Acc77, \n",
    "# 4 for SCADA+Acc17&38, 5 for SCADA+Acc17&38&77 \n",
    "duration = '24M'\n",
    "\n",
    "def NLL(y, distr): \n",
    "  return -distr.log_prob(y) \n",
    "\n",
    "def normal_sp(params): \n",
    "  return tfp.distributions.Normal(loc=params[:,0:2], scale=1e-3 \n",
    "                                  + tf.math.softplus(0.05 * params[:,2:4]))# both parameters are learnable\n",
    "\n",
    "kernel_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (52803 * 1.0)\n",
    "bias_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (52803 * 1.0)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(13,))\n",
    "\n",
    "hidden = tfp.layers.DenseFlipout(32,bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn,activation=\"relu\")(inputs)\n",
    "hidden = tfp.layers.DenseFlipout(64,bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn,activation=\"relu\")(hidden)\n",
    "hidden = tfp.layers.DenseFlipout(32,bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn,activation=\"relu\")(hidden)\n",
    "params = tfp.layers.DenseFlipout(4,bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn)(hidden)\n",
    "dist = tfp.layers.DistributionLambda(normal_sp)(params)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=dist)\n",
    "model.compile(Adam(learning_rate=0.0002), loss=NLL) \n",
    "\n",
    "model_params = Model(inputs=inputs, outputs=params)\n",
    "# model.summary()\n",
    "\n",
    "file = h5py.File('Weights/02_PredictionModel/Model%d_IncWave%s_%s.h5' % (modelID, include_wave, duration), 'r')\n",
    "weight = []\n",
    "for i in range(len(file.keys())):\n",
    "   weight.append(file['weight' + str(i)][:])\n",
    "model.set_weights(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions_pbnn(model, samples):\n",
    "    prediction_distribution= model(samples)\n",
    "    prediction_mean = np.squeeze(prediction_distribution.mean().numpy())/10\n",
    "    prediction_stdv = np.squeeze(prediction_distribution.stddev().numpy())/10\n",
    "\n",
    "    # The 95% CI is computed as mean Â± (1.96 * stdv)\n",
    "    upper = (prediction_mean + (1.96 * prediction_stdv))\n",
    "    lower = (prediction_mean - (1.96 * prediction_stdv))\n",
    "\n",
    "    \n",
    "    return prediction_mean, prediction_stdv, upper, lower\n",
    "\n",
    "def loglikelihood(y, loc, scale):\n",
    "    dist = tfp.distributions.Normal(loc, scale)\n",
    "    return -dist.log_prob(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normlaization of input data\n",
    "# Data normalization according to training dataset/ model\n",
    "filehandler = open('Weights/Norm', 'rb') \n",
    "std_scaler = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp02\n",
    "test_input = pd.read_pickle('DATA/mp02df_input')\n",
    "index = test_input.columns\n",
    "test_output = pd.read_pickle('DATA/mp02df_output')\n",
    "\n",
    "#In training samples\n",
    "X1 = np.zeros([5, 13]) \n",
    "Y1 = np.zeros([5, 2])\n",
    "intrain_input = test_input.loc[((test_input['windspeed'] == 10) | (test_input['windspeed'] == 12.6) \n",
    "                            | (test_input['windspeed'] == 15.5) | (test_input['windspeed'] == 16.9) | \n",
    "                            (test_input['windspeed'] == 20))\n",
    "                            & (test_input['max_TW_ACC_LAT077_FA'] > 0.02)\n",
    "                            & (test_input['max_TW_ACC_LAT077_FA'] <= 0.03)]\n",
    "intrain_input = intrain_input.sort_values(by=['windspeed'])\n",
    "intrain_input = intrain_input.drop_duplicates(subset=['windspeed'], keep='last')\n",
    "print(intrain_input.shape)\n",
    "intrain_output = test_output.reindex(intrain_input.index)\n",
    "print(intrain_output.shape)\n",
    "# Retrive features based on the modelID_\n",
    "index1 = pd.core.indexes.base.Index([]) # create a blank index array\n",
    "if modelID == 3: # Acc77\n",
    "    index1 = index1.append(index[[7,8,13,14,19,20]])\n",
    "index1 = index1.append(index[21:]) # SCADA\n",
    "\n",
    "# Normalization\n",
    "inputn = pd.DataFrame(std_scaler.transform(intrain_input), columns=intrain_input.columns) \n",
    "outputn = intrain_output/10**6  #\n",
    "X1= inputn[index1].values\n",
    "Y1= outputn.values\n",
    "\n",
    "#Out of training samples\n",
    "X2 = np.zeros([5, 13]) \n",
    "Y2 = np.zeros([5, 2])\n",
    "outtrain_input = test_input.loc[((test_input['windspeed'] == 10) | (test_input['G08_windspeed'] == 12.6) \n",
    "                            | (test_input['windspeed'] == 15.5) | (test_input['windspeed'] == 16.9) | \n",
    "                            (test_input['windspeed'] == 20))\n",
    "                            & (test_input['max_TW_ACC_LAT077_FA'] > 0.15)\n",
    "                            & (test_input['max_TW_ACC_LAT077_FA'] <= 0.3)]\n",
    "outtrain_input = outtrain_input.sort_values(by=['windspeed'])\n",
    "outtrain_input = outtrain_input.drop_duplicates(subset=['windspeed'], keep='last')\n",
    "print(outtrain_input)\n",
    "outtrain_output = test_output.reindex(outtrain_input.index)\n",
    "print(outtrain_output.shape)\n",
    "# Normalization\n",
    "inputn = pd.DataFrame(std_scaler.transform(outtrain_input), columns=outtrain_input.columns) \n",
    "outputn = outtrain_output/10**6  #\n",
    "X2= inputn[index1].values\n",
    "Y2= outputn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X1)\n",
    "print(Y1)\n",
    "print(X2)\n",
    "print(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epistemic uncertainty\n",
    "   \n",
    "# cm = 1/2.54   \n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# plt.rcParams[\"font.size\"] = 9\n",
    "\n",
    "# cv_deml = np.zeros([100, 3])\n",
    "# cv_demn = np.zeros([100, 3])\n",
    "# for j in range(100):\n",
    "#     prediction_mean, prediction_stdv, upper, lower = compute_predictions_pbnn(model, X1)\n",
    "#     cv_deml[j, :] = prediction_stdv[:,0]/prediction_mean[:,0]\n",
    "#     cv_demn[j, :] = prediction_stdv[:,1]/prediction_mean[:,1]\n",
    "# M1_stdl = np.mean(cv_deml, axis = 0)\n",
    "# M1_stdn = np.mean(cv_demn, axis = 0)\n",
    "# V1_stdl = np.std(cv_deml, axis = 0)\n",
    "# V1_stdn = np.std(cv_demn, axis = 0)\n",
    "# print('MU = ',  V1_stdl/M1_stdl)\n",
    "# print('MU = ',  V1_stdn/M1_stdn)\n",
    "\n",
    "# cv_deml = np.zeros([100, 3])\n",
    "# cv_demn = np.zeros([100, 3])\n",
    "# for j in range(100):\n",
    "#     prediction_mean, prediction_stdv, upper, lower = compute_predictions_pbnn(model, X2)\n",
    "#     cv_deml[j, :] = prediction_stdv[:,0]/prediction_mean[:,0]\n",
    "#     cv_demn[j, :] = prediction_stdv[:,1]/prediction_mean[:,1]\n",
    "# M2_stdl = np.mean(cv_deml, axis = 0)\n",
    "# M2_stdn = np.mean(cv_demn, axis = 0)\n",
    "# V2_stdl = np.std(cv_deml, axis = 0)\n",
    "# V2_stdn = np.std(cv_demn, axis = 0)\n",
    "# print('MU = ',  V2_stdl/M2_stdl)\n",
    "# print('MU = ',  V2_stdn/M2_stdn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictive uncertainty\n",
    "   \n",
    "cm = 1/2.54   \n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 9\n",
    "\n",
    "deml = np.zeros([100, len(Y1)])\n",
    "demn = np.zeros([100, len(Y1)])\n",
    "for j in range(100):\n",
    "    dems = model.predict(X1)\n",
    "    deml[j, :] = dems[:,0]/10\n",
    "    demn[j, :] = dems[:,1]/10\n",
    "M1_l = np.mean(deml, axis = 0)\n",
    "M1_n = np.mean(demn, axis = 0)\n",
    "V1_l = np.std(deml, axis = 0)\n",
    "V1_n = np.std(demn, axis = 0)\n",
    "print('PU = ',  V1_stdl/M1_stdl)\n",
    "print('PU = ',  V1_stdn/M1_stdn)\n",
    "\n",
    "deml = np.zeros([100, len(Y1)])\n",
    "demn = np.zeros([100, len(Y1)])\n",
    "for j in range(100):\n",
    "    dems = model.predict(X2)\n",
    "    deml[j, :] = dems[:,0]/10\n",
    "    demn[j, :] = dems[:,1]/10\n",
    "M2_l = np.mean(deml, axis = 0)\n",
    "M2_n = np.mean(demn, axis = 0)\n",
    "V2_l = np.std(deml, axis = 0)\n",
    "V2_n = np.std(demn, axis = 0)\n",
    "print('PU = ',  V2_stdl/M2_stdl)\n",
    "print('PU = ',  V2_stdn/M2_stdn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic Model\n",
    "VSnet = load_model('Weights/01_SensorPlacementTest/DNNModel%s_IncWave%s.h5' % (modelID, include_wave))\n",
    "dnn_output1 = VSnet.predict(X1)\n",
    "dnn_output2 = VSnet.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 1/2.54  # centimeters in inches\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 9\n",
    "x_test = np.array([10, 12.6, 14.9, 16.9, 20])\n",
    "fig1, ax = plt.subplots(2, figsize=(8.5*cm, 7*cm), sharey='row', dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(left=0.15, right=.98, top=0.98, bottom=0.15, hspace = 0.1, wspace=0.15)\n",
    "ax[0].scatter(x_test,Y1[:,0], color = '#cb181d', marker='o', facecolor='white')\n",
    "ax[0].scatter(x_test,dnn_output1[:,0], marker = 'x', color = 'black')\n",
    "ax[0].errorbar(x_test,M1_l, 1.96*V1_l, marker='_', linestyle='none', capsize=5, label=r'Prediction (Mean $\\pm$ 1.96 Std)')\n",
    "ax[1].scatter(x_test,Y1[:,1], color = '#cb181d', marker='o', facecolor='white')\n",
    "ax[1].scatter(x_test,dnn_output1[:,1], marker = 'x', color = 'black')\n",
    "ax[1].errorbar(x_test,M1_n, 1.96*V1_n, marker='_', linestyle='none', capsize=5, label=r'Prediction (Mean $\\pm$ 1.96 Std)')\n",
    "ax[0].set_yticklabels([])\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_ylim([0,0.65])\n",
    "ax[0].set_ylabel('DEM$_{tl}$')   \n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_ylim([0,0.65])\n",
    "ax[1].set_ylabel('DEM$_{tn}$')\n",
    "ax[1].set_xlabel('Wind speed (m/s)')\n",
    "ax[0].legend(['Measured', 'DNN', 'BNN'], ncol=3, loc = 'upper left')\n",
    "fig1.savefig('Figures/04_FarmwideApplication/MP02Intrain_DNN_BNN.pdf')\n",
    "\n",
    "fig2, ax = plt.subplots(2, figsize=(8.5*cm, 7*cm), sharey='row', dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(left=0.15, right=.98, top=0.98, bottom=0.15, hspace = 0.1, wspace=0.15)\n",
    "ax[0].scatter(x_test, Y2[:,0], color = '#cb181d', marker='o', facecolor='white')\n",
    "ax[0].scatter(x_test, dnn_output2[:,0], marker = 'x', color = 'black')\n",
    "ax[0].errorbar(x_test, M2_l, 1.96*V2_l, marker='_', linestyle='none', capsize=5, label=r'Prediction (Mean $\\pm$ 1.96 Std)')\n",
    "ax[1].scatter(x_test,Y2[:,1], color = '#cb181d', marker='o', facecolor='white')\n",
    "ax[1].scatter(x_test,dnn_output2[:,1], marker = 'x', color = 'black')\n",
    "ax[1].errorbar(x_test,M2_n, 1.96*V2_n, marker='_', linestyle='none', capsize=5, label=r'Prediction (Mean $\\pm$ 1.96 Std)')\n",
    "ax[0].set_yticklabels([])\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_ylim([0,0.65])\n",
    "ax[0].set_ylabel('DEM$_{tl}$')   \n",
    "ax[1].set_yticklabels([])\n",
    "ax[1].set_ylim([0,0.65])\n",
    "ax[1].set_ylabel('DEM$_{tn}$')\n",
    "ax[1].set_xlabel('Wind speed (m/s)')\n",
    "ax[0].legend(['Measured', 'DNN', 'BNN'], ncol=3, loc = 'upper left')\n",
    "fig2.savefig('Figures/04_FarmwideApplication/MP02Outtrain_DNN_BNN.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
