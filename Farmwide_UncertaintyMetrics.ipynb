{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from os import walk\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_wave = 'no'\n",
    "modelID = 3\n",
    "# (0 for SCADA only, 1 for SCADA+Acc17, 2 for SCADA+Acc38, 3 for SCADA+Acc77, \n",
    "# 4 for SCADA+Acc17&38, 5 for SCADA+Acc17&38&77 \n",
    "duration = '24M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLL(y, distr): \n",
    "  return -distr.log_prob(y) \n",
    "\n",
    "def normal_sp(params): \n",
    "  return tfp.distributions.Normal(loc=params[:,0:2], scale=1e-3 \n",
    "                                  + tf.math.softplus(0.05 * params[:,2:4]))# both parameters are learnable\n",
    "\n",
    "kernel_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (52803 * 1.0)\n",
    "bias_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (52803 * 1.0)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(13,))\n",
    "\n",
    "hidden = tfp.layers.DenseFlipout(32,bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn,activation=\"relu\")(inputs)\n",
    "hidden = tfp.layers.DenseFlipout(64,bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn,activation=\"relu\")(hidden)\n",
    "hidden = tfp.layers.DenseFlipout(32,bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn,activation=\"relu\")(hidden)\n",
    "params = tfp.layers.DenseFlipout(4,bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn)(hidden)\n",
    "dist = tfp.layers.DistributionLambda(normal_sp)(params)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=dist)\n",
    "model.compile(Adam(learning_rate=0.0002), loss=NLL) \n",
    "\n",
    "model_params = Model(inputs=inputs, outputs=params)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('Weights/02_PredictionModel/Model%d_IncWave%s_%s.h5' % (modelID, include_wave, duration), 'r')\n",
    "weight = []\n",
    "for i in range(len(file.keys())):\n",
    "   weight.append(file['weight' + str(i)][:])\n",
    "model.set_weights(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions_pbnn(model, samples):\n",
    "    prediction_distribution= model(samples)\n",
    "    prediction_mean = np.squeeze(prediction_distribution.mean().numpy())/10\n",
    "    prediction_stdv = np.squeeze(prediction_distribution.stddev().numpy())/10\n",
    "\n",
    "    # The 95% CI is computed as mean Â± (1.96 * stdv)\n",
    "    upper = (prediction_mean + (1.96 * prediction_stdv))\n",
    "    lower = (prediction_mean - (1.96 * prediction_stdv))\n",
    "\n",
    "    \n",
    "    return prediction_mean, prediction_stdv, upper, lower\n",
    "\n",
    "def loglikelihood(y, loc, scale):\n",
    "    dist = tfp.distributions.Normal(loc, scale)\n",
    "    return dist.log_prob(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 1/2.54  # centimeters in inches\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 9\n",
    "fig1, ax1 = plt.subplots(1, figsize=(8.5*cm, 7.5*cm), sharey='row', dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(left=0.2, right=.98, top=0.98, bottom=0.3, hspace = 0.65, wspace=0.15)\n",
    "fig2, ax2 = plt.subplots(1, figsize=(8.5*cm, 7.5*cm), sharey='row', dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplots_adjust(left=0.2, right=.98, top=0.98, bottom=0.3, hspace = 0.65, wspace=0.15)\n",
    "\n",
    "input_files = ['train_input','test_input','mp01df_input','mp02df_input']\n",
    "output_files = ['train_output','test_output','mp01df_output','mp02df_output']\n",
    "# input_files = ['test_input']\n",
    "# output_files = ['test_output']\n",
    "for ind in range(len(input_files)):\n",
    "    test_input = pd.read_pickle('DATA/%s'%(input_files[ind]))\n",
    "    test_output = pd.read_pickle('DATA/%s'%(output_files[ind]))\n",
    "    index = test_input.columns\n",
    "\n",
    "    # Normlaization of input data\n",
    "    # Data normalization according to training dataset/ model\n",
    "    filehandler = open('Weights/Norm', 'rb') \n",
    "    std_scaler = pickle.load(filehandler)\n",
    "    inputn = pd.DataFrame(std_scaler.transform(test_input), columns=test_input.columns) \n",
    "    outputn = test_output/10**6  # \n",
    "    \n",
    "    # Retrive features based on the modelID\n",
    "    index1 = pd.core.indexes.base.Index([]) # create a blank index array\n",
    "    if modelID == 3: # Acc77\n",
    "        index1 = index1.append(index[[7,8,13,14,19,20]])\n",
    "    index1 = index1.append(index[21:]) # SCADA\n",
    "    X = inputn[index1].values\n",
    "    Y = outputn.values\n",
    "    \n",
    "    nsim = 10000\n",
    "    DEM_tl = np.zeros([len(X)])\n",
    "    DEM_tn = np.zeros([len(X)])\n",
    "    DEM_tl2 = np.zeros([len(X)])\n",
    "    DEM_tn2 = np.zeros([len(X)])\n",
    "    mu_tl = np.zeros([len(X)])\n",
    "    mu_tn = np.zeros([len(X)])\n",
    "    mu_tl2 = np.zeros([len(X)])\n",
    "    mu_tn2 = np.zeros([len(X)])\n",
    "    sigma_tl = np.zeros([len(X)])\n",
    "    sigma_tn = np.zeros([len(X)])\n",
    "    sigma_tl2 = np.zeros([len(X)])\n",
    "    sigma_tn2 = np.zeros([len(X)])\n",
    "    ll_tl = np.zeros([len(X)])\n",
    "    ll_tn = np.zeros([len(X)])\n",
    "    for j in range(nsim):\n",
    "#         np.random.seed(j)\n",
    "        dems = model.predict(X)\n",
    "        DEM_tl += dems[:,0]/10\n",
    "        DEM_tn += dems[:,1]/10\n",
    "        DEM_tl2 += (dems[:,0]/10)**2\n",
    "        DEM_tn2 += (dems[:,1]/10)**2\n",
    "        prediction_mean, prediction_stdv, upper, lower = compute_predictions_pbnn(model, X)\n",
    "        mu_tl += prediction_mean[:,0]\n",
    "        mu_tn += prediction_mean[:,1]\n",
    "        mu_tl2 += (prediction_mean[:,0])**2\n",
    "        mu_tn2 += (prediction_mean[:,1])**2\n",
    "        sigma_tl += (prediction_stdv[:,0])**2\n",
    "        sigma_tn += (prediction_stdv[:,1])**2\n",
    "        sigma_tl2 += ((prediction_stdv[:,0])**2)**2\n",
    "        sigma_tn2 += ((prediction_stdv[:,1])**2)**2\n",
    "        lls = loglikelihood(Y, prediction_mean, prediction_stdv)\n",
    "        ll_tl += lls[:,0]\n",
    "        ll_tn += lls[:,1]\n",
    "    \n",
    "    \n",
    "    M_tl = (DEM_tl/nsim)\n",
    "    M_tn = (DEM_tn/nsim)\n",
    "    V_tl = (DEM_tl2/nsim)-(DEM_tl/nsim)**2\n",
    "    V_tn = (DEM_tn2/nsim)-(DEM_tn/nsim)**2\n",
    "    \n",
    "    Mmu_tl = (mu_tl/nsim)\n",
    "    Mmu_tn = (mu_tn/nsim)\n",
    "    Vmu_tl = (mu_tl2/nsim)-(mu_tl/nsim)**2\n",
    "    Vmu_tn = (mu_tn2/nsim)-(mu_tn/nsim)**2\n",
    "    \n",
    "    Msigma_tl = sigma_tl/nsim\n",
    "    Msigma_tn = sigma_tn/nsim\n",
    "    Vsigma_tl = (sigma_tl2/nsim)-(sigma_tl/nsim)**2 \n",
    "    Vsigma_tn = (sigma_tn2/nsim)-(sigma_tn/nsim)**2 \n",
    "    \n",
    "    LL_tl = ll_tl.numpy()/nsim\n",
    "    LL_tn = ll_tn.numpy()/nsim\n",
    "    sio.savemat('%s_7metrics_10000.mat'%(input_files[ind]),{'M_tl':M_tl, 'M_tn':M_tn, \n",
    "                                                      'V_tl':V_tl, 'V_tn':V_tn,\n",
    "                                                      'Mmu_tl':Mmu_tl, 'Mmu_tn':Mmu_tn, \n",
    "                                                      'Vmu_tl':Vmu_tl, 'Vmu_tn':Vmu_tn, \n",
    "                                                      'Msigma_tl':Msigma_tl, 'Msigma_tn':Msigma_tn,\n",
    "                                                      'Vsigma_tl':Vsigma_tl, 'Vsigma_tn':Vsigma_tn,\n",
    "                                                      'LL_tl':LL_tl, 'LL_tn':LL_tn})\n",
    "\n",
    "#     print(LL_tl)\n",
    "    print('MU',Vmu_tl/V_tl)\n",
    "    print('AU',sigma_tl/nsim/V_tl)\n",
    "    print('MU Fraction',Vmu_tl/V_tl)\n",
    "    print('AU Fraction',sigma_tl/nsim)\n",
    "    bp1 = ax1.boxplot(np.transpose(V_tl), positions = [ind], patch_artist = True, widths = 0.35, meanline = True, \n",
    "                whis = [2.5,97.5], boxprops=dict(facecolor='#deebf7'), showfliers=False, showmeans=True, \n",
    "                medianprops = dict(linewidth=0, ls='-'), meanprops=dict(color='red'))\n",
    "    bp2 = ax1.boxplot(np.transpose(V_tn), positions = [ind+0.35], patch_artist = True, widths = 0.35, meanline = True, \n",
    "                whis = [2.5,97.5], boxprops=dict(facecolor='#3182bd'), showfliers=False, showmeans=True,\n",
    "                medianprops = dict(linewidth=0, ls='-'), meanprops=dict(color='red'))\n",
    "\n",
    "    bp3 = ax2.boxplot(np.transpose(Vmu_tl), positions = [ind], patch_artist = True, widths = 0.35, meanline = True, \n",
    "                whis = [2.5,97.5], boxprops=dict(facecolor='#deebf7'), showfliers=False, showmeans=True, \n",
    "                medianprops = dict(linewidth=0, ls='-'), meanprops=dict(color='red'))\n",
    "    bp4 = ax2.boxplot(np.transpose(Vmu_tn), positions = [ind+0.35], patch_artist = True, widths = 0.35, meanline = True, \n",
    "                whis = [2.5,97.5], boxprops=dict(facecolor='#3182bd'), showfliers=False, showmeans=True, \n",
    "                medianprops = dict(linewidth=0,  ls='-'), meanprops=dict(color='red'))\n",
    "\n",
    "ax1.legend([bp1[\"boxes\"][0], bp2[\"boxes\"][0]], [r'DEM$_{tl}$', r'DEM$_{tn}$'], loc='upper left')\n",
    "# ax1.set_ylim([-1, 1])\n",
    "ax1.set_xticks([0.2,1.2,2.2,3.2])\n",
    "ax1.set_xticklabels(['Fleet-leader (train)','Fleet-leader (test)','MP01 (test)','MP02 (test)'], horizontalalignment= 'right', rotation=45)     \n",
    "ax1.set_ylabel(r'$\\mathrm{\\mathbf{\\mathbb{H}}}}$ [DEM]')\n",
    "\n",
    "\n",
    "ax2.legend([bp3[\"boxes\"][0], bp4[\"boxes\"][0]], [r'DEM$_{tl}$', r'DEM$_{tn}$'], loc='lower left')\n",
    "ax2.set_xticks([0.2,1.2,2.2,3.2])\n",
    "ax2.set_xticklabels(['Fleet-leader (train)','Fleet-leader (test)','MP01 (test)','MP02 (test)'], horizontalalignment= 'right', rotation=45)   \n",
    "ax2.set_ylabel(r'$\\mathrm{\\mathbf{\\mathbb{E}}}}$ [$\\mathrm{\\mathbf{\\mathcal{L}}}}$]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
